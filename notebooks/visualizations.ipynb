{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchio as tio\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "from segmentation_pipeline import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"../configs/diffusion_hippocampus.py\")\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI_cropped/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 400\n",
    "file_path = f\"X:\\\\Checkpoints\\\\Diffusion_MRI\\\\dmri-hippo-seg-debugging\\\\dmri-hippo-cycle-flash-1q798mvn\\\\best_checkpoints\\\\iter{iteration:08}.pt\"\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = TorchContext(device, file_path=file_path, variables=variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 118\n",
    "file_path = f\"X:\\\\Checkpoints\\\\MSSEG2\\\\msseg2-hooks-capacitor-2oachxos\\\\iter{iteration:08}.pt\"\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/MSSEG2_resampled/\")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "context = TorchContext(device, file_path=file_path, variables=variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/msseg2.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/MSSEG2_processed/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cefir\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce822af0e8974da69a684e7c3a64beb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='name', options=('ab300_001', 'ab300_002', 'ab300_003', 'ab300_004'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = context.dataset\n",
    "all_subject_names = list(dataset.all_subjects_map.keys())\n",
    "\n",
    "noise = tio.RandomNoise(std=0.035, p=0.3)\n",
    "blur = tio.RandomBlur((0, 1), p=0.2)\n",
    "augmentations = tio.Compose([\n",
    "    tio.RandomFlip(axes=(0, 1, 2)),\n",
    "    tio.RandomElasticDeformation(p=0.5, num_control_points=(7, 7, 4), locked_borders=1, image_interpolation='bspline'),\n",
    "    tio.RandomBiasField(p=0.5),\n",
    "    tio.RescaleIntensity((0, 1), (0.01, 99.9)),\n",
    "    tio.RandomGamma(p=0.8),\n",
    "    tio.RescaleIntensity((-1, 1)),\n",
    "    tio.OneOf([\n",
    "        tio.Compose([blur, noise]),\n",
    "        tio.Compose([noise, blur]),\n",
    "    ])\n",
    "])\n",
    "#augmentations = ReconstructMeanDWI(num_dwis=(1, 25), num_directions=(1, 3), directionality=(4, 10))\n",
    "\n",
    "custom_transform = tio.Compose([\n",
    "    tio.CropOrPad((96, 88, 24), padding_mode='edge', mask_name='whole_roi_union'),\n",
    "    MergeLabels([('left_whole', 'right_whole')], right_masking_method=\"Right\", include=\"whole_roi\"),\n",
    "    augmentations,\n",
    "    tio.RescaleIntensity((-1., 1.), (0.5, 99.5)),\n",
    "    ConcatenateImages(image_names=[\"mean_dwi\", \"md\", \"fa\"], image_channels=[1, 1, 1], new_image_name=\"X\"),\n",
    "    RenameProperty(old_name=\"whole_roi\", new_name=\"y\"),\n",
    "    CustomOneHot(include=\"y\")\n",
    "])\n",
    "#custom_transform = context.dataset.transforms['training']\n",
    "\n",
    "@interact(name=all_subject_names, \n",
    "          mode=['vis_subject', 'model_contour', 'vis_model'],\n",
    "          randomize=False)\n",
    "def vis(name, mode, randomize):\n",
    "    context.model.eval()\n",
    "    \n",
    "    def get_subject():\n",
    "        if custom_transform is None:\n",
    "            subject = context.dataset[name]\n",
    "        else:\n",
    "            subject = context.dataset.all_subjects_map[name]\n",
    "            subject = copy.deepcopy(subject)\n",
    "            subject = custom_transform(subject)\n",
    "        return subject\n",
    "    \n",
    "    \n",
    "    if mode == 'vis_subject':\n",
    "        \n",
    "        #augmentation = tio.RandomAffine(scales=0.2, degrees=45)\n",
    "        #augmentation = tio.RandomElasticDeformation()\n",
    "        #subject = augmentation(subject)\n",
    "        \n",
    "        vis_subject(context, [get_subject() for i in range(4)])\n",
    "    \n",
    "    elif mode == 'model_contour':\n",
    "        #subject = tio.CropOrPad((96, 96, 96))(subject)\n",
    "        subject = tio.EnsureShapeMultiple(32)(subject)\n",
    "        \n",
    "        X = subject['X']['data'][None].to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = context.model(X)[0]\n",
    "            y_pred = y_pred > 0.5\n",
    "        subject['y_pred'] = copy.deepcopy(subject['y'])\n",
    "        subject['y_pred'].set_data(y_pred)\n",
    "            \n",
    "        vis_subject(context, subject)\n",
    "   \n",
    "    elif mode == 'vis_model':\n",
    "        subject = tio.CropOrPad((96, 96, 96))(subject)\n",
    "        vis_model(context, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in context.dataset:\n",
    "    time01 = subject['flair_time01'].data\n",
    "    time01 = subject['flair_time01'].data\n",
    "    print(subject['name'], subject['flair_time01'], time01.mean(), time01.std(), time01.min(), time01.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in context.dataset:\n",
    "    print(subject['name'], subject['flair_time01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = context.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask = subject['hbt_roi'].data.bool()[0]\n",
    "W, H, D = mask.shape\n",
    "W_where, H_where, D_where = torch.where(mask)\n",
    "\n",
    "slice_ids, counts = torch.unique(W_where, return_counts=True)\n",
    "interesting_slice_ids_ids = torch.argsort(counts, descending=True)\n",
    "interesting_slice_ids = slice_ids[interesting_slice_ids_ids]\n",
    "\n",
    "print(interesting_slice_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = FindInterestingSlice()(subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject['y']['interesting_slice_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1)\n",
    "x.dtype == torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "\n",
    "fold_ids = [i % 5 for i in range(42)]\n",
    "Random(0).shuffle(fold_ids)\n",
    "fold_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = torch.ones(3, 5, 7)\n",
    "\n",
    "perm = (1, 2, 0)\n",
    "x = x.permute(perm)\n",
    "\n",
    "inverse_perm = tuple(torch.argsort(torch.tensor(perm)).tolist())\n",
    "print(inverse_perm)\n",
    "x = x.permute(inverse_perm)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "list(permutations((0, 1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "low, high = 1, 25\n",
    "exponent = 2\n",
    "sample = np.random.rand(10000)\n",
    "sample = sample ** exponent\n",
    "sample = sample * (high - low + 1) + low\n",
    "sample = sample.astype(int)\n",
    "print(sample.min(), sample.max())\n",
    "\n",
    "plt.hist(sample, bins=(high - low + 1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
