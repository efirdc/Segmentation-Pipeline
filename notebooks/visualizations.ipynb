{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchio as tio\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "from segmentation_pipeline import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.dmri_hippo.configs.main_config import get_context\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI_cropped/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 400\n",
    "file_path = f\"X:\\\\Checkpoints\\\\Diffusion_MRI\\\\dmri-hippo-seg-debugging\\\\dmri-hippo-cycle-flash-1q798mvn\\\\best_checkpoints\\\\iter{iteration:08}.pt\"\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = TorchContext(device, file_path=file_path, variables=variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 118\n",
    "file_path = f\"X:\\\\Checkpoints\\\\MSSEG2\\\\msseg2-hooks-capacitor-2oachxos\\\\iter{iteration:08}.pt\"\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/MSSEG2_resampled/\")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "context = TorchContext(device, file_path=file_path, variables=variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/msseg2.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/MSSEG2_processed/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a7cce2b53b483a8da170bd7b1ffab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='name', options=('ab300_001', 'ab300_002', 'ab300_003', 'ab300_004'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = context.dataset\n",
    "all_subject_names = list(dataset.all_subjects_map.keys())\n",
    "\n",
    "noise = tio.RandomNoise(std=0.035, p=0.3)\n",
    "blur = tio.RandomBlur((0, 1), p=0.2)\n",
    "augmentations = tio.Compose([\n",
    "    tio.RandomFlip(axes=(0, 1, 2)),\n",
    "    tio.RandomElasticDeformation(p=0.5, num_control_points=(7, 7, 4), locked_borders=1, image_interpolation='bspline'),\n",
    "    tio.RandomBiasField(p=0.5),\n",
    "    tio.RescaleIntensity((0, 1), (0.01, 99.9)),\n",
    "    tio.RandomGamma(p=0.8),\n",
    "    tio.RescaleIntensity((-1, 1)),\n",
    "    tio.OneOf([\n",
    "        tio.Compose([blur, noise]),\n",
    "        tio.Compose([noise, blur]),\n",
    "    ])\n",
    "])\n",
    "augmentations = ReconstructMeanDWI(num_dwis=(1, 7), num_directions=(1, 3), directionality=(4, 10))\n",
    "\n",
    "custom_transform = tio.Compose([\n",
    "    tio.CropOrPad((96, 88, 24), padding_mode='edge', mask_name='whole_roi_union'),\n",
    "    MergeLabels([('left_whole', 'right_whole')], right_masking_method=\"Right\", include=\"whole_roi\"),\n",
    "    augmentations,\n",
    "    tio.RescaleIntensity((-1., 1.), (0.5, 99.5)),\n",
    "    ConcatenateImages(image_names=[\"mean_dwi\", \"md\", \"fa\"], image_channels=[1, 1, 1], new_image_name=\"X\"),\n",
    "    RenameProperty(old_name=\"whole_roi\", new_name=\"y\"),\n",
    "    CustomOneHot(include=\"y\")\n",
    "])\n",
    "#custom_transform = context.dataset.transforms['training']\n",
    "\n",
    "@interact(name=all_subject_names, \n",
    "          mode=['vis_subject', 'model_contour', 'vis_model'],\n",
    "          randomize=False)\n",
    "def vis(name, mode, randomize):\n",
    "    context.model.eval()\n",
    "    \n",
    "    def get_subject():\n",
    "        if custom_transform is None:\n",
    "            subject = context.dataset[name]\n",
    "        else:\n",
    "            subject = context.dataset.all_subjects_map[name]\n",
    "            subject = copy.deepcopy(subject)\n",
    "            subject = custom_transform(subject)\n",
    "        return subject\n",
    "    \n",
    "    \n",
    "    if mode == 'vis_subject':\n",
    "        \n",
    "        #augmentation = tio.RandomAffine(scales=0.2, degrees=45)\n",
    "        #augmentation = tio.RandomElasticDeformation()\n",
    "        #subject = augmentation(subject)\n",
    "        \n",
    "        vis_subject(context, [get_subject() for i in range(4)])\n",
    "    \n",
    "    elif mode == 'model_contour':\n",
    "        #subject = tio.CropOrPad((96, 96, 96))(subject)\n",
    "        subject = tio.EnsureShapeMultiple(32)(subject)\n",
    "        \n",
    "        X = subject['X']['data'][None].to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = context.model(X)[0]\n",
    "            y_pred = y_pred > 0.5\n",
    "        subject['y_pred'] = copy.deepcopy(subject['y'])\n",
    "        subject['y_pred'].set_data(y_pred)\n",
    "            \n",
    "        vis_subject(context, subject)\n",
    "   \n",
    "    elif mode == 'vis_model':\n",
    "        subject = tio.CropOrPad((96, 96, 96))(subject)\n",
    "        vis_model(context, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in context.dataset:\n",
    "    time01 = subject['flair_time01'].data\n",
    "    time01 = subject['flair_time01'].data\n",
    "    print(subject['name'], subject['flair_time01'], time01.mean(), time01.std(), time01.min(), time01.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in context.dataset:\n",
    "    print(subject['name'], subject['flair_time01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = context.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask = subject['hbt_roi'].data.bool()[0]\n",
    "W, H, D = mask.shape\n",
    "W_where, H_where, D_where = torch.where(mask)\n",
    "\n",
    "slice_ids, counts = torch.unique(W_where, return_counts=True)\n",
    "interesting_slice_ids_ids = torch.argsort(counts, descending=True)\n",
    "interesting_slice_ids = slice_ids[interesting_slice_ids_ids]\n",
    "\n",
    "print(interesting_slice_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = FindInterestingSlice()(subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject['y']['interesting_slice_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1)\n",
    "x.dtype == torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "\n",
    "fold_ids = [i % 5 for i in range(42)]\n",
    "Random(0).shuffle(fold_ids)\n",
    "fold_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = torch.ones(3, 5, 7)\n",
    "\n",
    "perm = (1, 2, 0)\n",
    "x = x.permute(perm)\n",
    "\n",
    "inverse_perm = tuple(torch.argsort(torch.tensor(perm)).tolist())\n",
    "print(inverse_perm)\n",
    "x = x.permute(inverse_perm)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "list(permutations((0, 1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 7 2.9059 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cefir\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "low, high = 1, 7\n",
    "exponent = 2\n",
    "sample = np.random.rand(10000)\n",
    "#sample = np.random.pareto(a=exponent, size=10000)\n",
    "sample = sample ** exponent\n",
    "sample = sample * (high - low + 1) + low\n",
    "sample = sample.astype(int)\n",
    "print(sample.min(), sample.max(), sample.mean(), np.median(sample))\n",
    "\n",
    "plt.hist(sample, bins=(high - low + 1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
