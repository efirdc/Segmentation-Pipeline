{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "molecular-institute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from utils import load_module\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/diffusion_hippocampus.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/qsm_deep_grey_matter.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/DGM/segmentation_3T_ps18_v3/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "animated-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/msseg2.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/MSSEG2_processed/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "loving-sympathy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "32 8\n"
     ]
    }
   ],
   "source": [
    "len(context.dataset)\n",
    "\n",
    "training_dataset = context.dataset.get_cohort_dataset(\"training\")\n",
    "validation_dataset = context.dataset.get_cohort_dataset('validation')\n",
    "\n",
    "validation_filter = context.trainer.get_filter_from_scheduled_evaluations(\n",
    "    context.dataset, \n",
    "    context.trainer.validation_evaluators,\n",
    "    include_fold_filters=False\n",
    ")\n",
    "\n",
    "print(validation_filter.filters)\n",
    "validation_dataset.set_cohort(validation_filter)\n",
    "\n",
    "print(len(training_dataset), len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "\n",
    "for i in range(len(context.dataset)):\n",
    "    \n",
    "    '''\n",
    "    untransformed_subject = context.dataset.subjects[i]\n",
    "    \n",
    "    image_dict = untransformed_subject.get_images_dict(intensity_only=False)\n",
    "    \n",
    "    print(untransformed_subject.name)\n",
    "    for (image_name1, image1), (image_name2, image2) in combinations(image_dict.items(), 2):\n",
    "        print(f'{image_name1}.affine - {image_name2}.affine')\n",
    "        print(image1.affine - image2.affine)'''\n",
    "    \n",
    "    subject = context.dataset[i]\n",
    "    \n",
    "    print(subject.name)\n",
    "    print(subject.spacing, subject.spatial_shape)\n",
    "    \n",
    "    patch_size=96\n",
    "    sampler = tio.GridSampler(subject=subject, patch_size=patch_size, patch_overlap=patch_size // 2, padding_mode=None)\n",
    "    print(\"num_patches =\", len(sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms import *\n",
    "import copy\n",
    "\n",
    "for i in range(len(context.dataset)):\n",
    "    subject = context.dataset.subjects[i]\n",
    "    subject = copy.deepcopy(subject)\n",
    "    \n",
    "    pre_spacing = subject.get_first_image().spacing\n",
    "    \n",
    "    iso_resample = IsotropicResample(spacing_mode='median', tolerance=0.15)\n",
    "    subject = iso_resample(subject)\n",
    "    post_spacing = subject.get_first_image().spacing\n",
    "    \n",
    "    pre_spacing = tuple([round(s, 3) for s in pre_spacing])\n",
    "    post_spacing = tuple([round(s, 3) for s in post_spacing])\n",
    "    \n",
    "    print(pre_spacing, post_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchio as tio\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "patch_size = 96\n",
    "queue_length = 300\n",
    "samples_per_volume = 10\n",
    "\n",
    "sampler = tio.data.UniformSampler(patch_size)\n",
    "patches_queue = tio.Queue(\n",
    "    context.dataset,\n",
    "    queue_length,\n",
    "    samples_per_volume,\n",
    "    sampler,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "patches_loader = DataLoader(dataset=patches_queue, batch_size=2, collate_fn=context.dataset.collate)\n",
    "\n",
    "num_epochs = 2\n",
    "model = torch.nn.Identity()\n",
    "for epoch_index in range(num_epochs):\n",
    "    for patches_batch in patches_loader:\n",
    "        print(patches_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in context.dataset.all_subjects:\n",
    "    img = subject['flair_time01']\n",
    "    img.load()\n",
    "    print(img.spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "#print(inspect.getsourcefile(context.model.__class__))\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-expression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasd_dataset = context.dataset.get_cohort_dataset('fasd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasd_dataset.preload_and_transform_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "untransformed_subject = context.dataset.subjects[0]\n",
    "print(\"Original labels:\")\n",
    "print(untransformed_subject['whole_roi']['label_values'])\n",
    "\n",
    "subject = context.dataset[0]\n",
    "print(\"\\nTransformed labels:\")\n",
    "print(subject['y']['label_values'])\n",
    "\n",
    "inverse_subject = subject.apply_inverse_transform(warn=False)\n",
    "print(\"\\nInverse transformed labels:\")\n",
    "print(inverse_subject['y']['label_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in context.dataset[1].items():\n",
    "    print(key, value, type(value))\n",
    "    if isinstance(value, dict):\n",
    "        for key, value2 in value.items():\n",
    "            print(key, value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "           \n",
    "for i in range(2):\n",
    "    loader = sample_data(context.dataloader)\n",
    "    batch = next(loader)\n",
    "    for key, val in batch.items():\n",
    "        print(key, val.shape, val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(20, 20, 20)\n",
    "for y in x.split([3, 2, 5, 10]):\n",
    "    print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"test-project-2\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    log_dict = {\n",
    "        'something': {\n",
    "            foo: {'mean': random.random(), 'std': random.random()}\n",
    "            for foo in \"ABC\"\n",
    "        }\n",
    "    }\n",
    "    wandb.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(10):\n",
    "    evaluation = {}\n",
    "    \n",
    "    for structure in (\"A\", \"B\", \"C\"):\n",
    "        columns = [\"TP\", \"FP\", \"TN\", \"FN\", 'dice', \"jaccard\"]\n",
    "        S = 25\n",
    "        subjects = [f'subject_{i:01}' for i in range(S)]\n",
    "\n",
    "        df = pd.DataFrame(data=np.random.randint(50, 100, size=(S, 4)), columns=[\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "        df.insert(loc=0, column='Subject', value=subjects)\n",
    "\n",
    "        TP, FP, TN, FN = df[\"TP\"], df[\"FP\"], df[\"TN\"], df[\"FN\"]\n",
    "\n",
    "        df['dice'] = 2 * TP / (2 * TP + FP + FN)\n",
    "        df['jaccard'] = TP / (TP + FP + FN)\n",
    "        evaluation[f\"Structure {structure}\"] = wandb.Table(dataframe=df)\n",
    "        \n",
    "    wandb.log({f'Segmentation Evaluation': evaluation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'X:\\Datasets\\Diffusion_MRI\\Attributes\\demographics.xlsx'\n",
    "df = pd.read_excel(file_path, index_col=0)\n",
    "#subject_col = df.columns[0]\n",
    "data = df.to_dict(orient='dict')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "print(pathlib.Path('yourPath.example').suffix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'X:\\Datasets\\DGM\\subject_attributes\\dgm_label_names.json'\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'X:\\Datasets\\DGM\\subject_attributes\\dgm_label_names.csv'\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "data = df.to_dict()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import is_sequence\n",
    "\n",
    "def test_func(*args):\n",
    "    if is_sequence(args) and len(args) == 1 and is_sequence(args[0]):\n",
    "        args = args[0]\n",
    "    print(args)\n",
    "    \n",
    "test_func(\"a\", \"b\", \"c\")\n",
    "test_func((\"a\", \"b\", \"c\"))\n",
    "test_func([\"a\", \"b\", \"c\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 0, 1]).bool()\n",
    "b = torch.tensor([1, 1, 0]).bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "import torch\n",
    "from evaluators import SegmentationEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "def pd_to_dict(elem):\n",
    "    if isinstance(elem, dict):\n",
    "        return {\n",
    "            key: pd_to_wandb(val)\n",
    "            for key, val in elem.items()\n",
    "        }\n",
    "    elif isinstance(elem, pd.DataFrame):\n",
    "        return elem.to_dict()\n",
    "    return elem\n",
    "\n",
    "def pd_to_wandb(elem):\n",
    "    if isinstance(elem, dict):\n",
    "        return {\n",
    "            key: pd_to_wandb(val)\n",
    "            for key, val in elem.items()\n",
    "        }\n",
    "    elif isinstance(elem, pd.DataFrame):\n",
    "        return wandb.Table(dataframe=elem)\n",
    "    return elem\n",
    "\n",
    "wandb.init(project=\"test-project-4\")\n",
    "for i in range(10):\n",
    "    label_values = {letter: val for val, letter in enumerate(\"ABCDE\")}\n",
    "\n",
    "    subjects = [\n",
    "        tio.Subject({\n",
    "            'name': f'subject_{i:02}',\n",
    "            'pred': tio.LabelMap(\n",
    "                tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "                label_values=label_values\n",
    "            ),\n",
    "            'target': tio.LabelMap(\n",
    "                tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "                label_values=label_values\n",
    "            ),\n",
    "        })\n",
    "        for i in range(20)\n",
    "    ]\n",
    "\n",
    "    seg_evaluator = SegmentationEvaluator(\n",
    "        prediction_label_name='pred', target_label_name='target', stats_to_output=['FP', 'TP', 'dice'], \n",
    "    )\n",
    "\n",
    "    log_dict = seg_evaluator(subjects)\n",
    "    wandb.log(pd_to_wandb(log_dict))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = tio.LabelMap(\n",
    "    tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "    label_values=label_values\n",
    ")\n",
    "\n",
    "tio.OneHot()(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10).unsqueeze(1)\n",
    "mask = torch.tensor([0, 1, 1, 0]).bool().unsqueeze(0)\n",
    "x, mask = torch.broadcast_tensors(x, mask)\n",
    "\n",
    "print(x.shape, mask.shape)\n",
    "\n",
    "x[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluators import VolumeStatsEvaluator\n",
    "import pandas as pd\n",
    "import torchio as tio\n",
    "\n",
    "\n",
    "label_values = {f'label_{letter}': (val + 1) for val, letter in enumerate(\"abcde\")}\n",
    "\n",
    "subjects = [\n",
    "    tio.Subject({\n",
    "        'name': f'subject_{i:02}',\n",
    "        'label': tio.LabelMap(\n",
    "            tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "            label_values=label_values\n",
    "        ),\n",
    "        'md': tio.ScalarImage(\n",
    "            tensor=torch.randn(size=(1, 20, 20, 20)) * 2 + 1,\n",
    "        ),\n",
    "        'fa': tio.ScalarImage(\n",
    "            tensor=torch.randn(size=(1, 20, 20, 20)) * 0.5 - 3,\n",
    "        ),\n",
    "    })\n",
    "    for i in range(20)\n",
    "]\n",
    "\n",
    "volume_stats_eval = VolumeStatsEvaluator(\n",
    "    label_map_name='label', image_names=['md', 'fa']\n",
    ")\n",
    "\n",
    "volume_stats_eval(subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "def merge_dicts(a, b):\n",
    "    merged_dict = {}\n",
    "    for key in a.keys():\n",
    "        if key in b:\n",
    "            merged_dict[key] = merge_dicts(a[key], b[key])\n",
    "        else:\n",
    "            merged_dict[key] = a[key]\n",
    "    for key in b.keys():\n",
    "        if key not in a:\n",
    "            merged_dict[key] = b[key]\n",
    "    return merged_dict\n",
    "\n",
    "dict1 = {'mean': {'hippo': {'md': {'subject_1': 1}}}}\n",
    "dict2 = {'mean': {'hippo': {'md': {'subject_2': 2}}}}\n",
    "dict3 = {'mean': {'hippo': {'fa': {'subject_1': 3}}}}\n",
    "dict4 = {'mean': {'hippo': {'fa': {'subject_2': 4}}}}\n",
    "\n",
    "out_dict = merge_dicts(dict1, dict2)\n",
    "\n",
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *\n",
    "\n",
    "train_dataset = context.dataset.get_cohort_dataset(\n",
    "    RequireAttributes({\"pathologies\": \"None\", \"protocol\": \"cbbrain\", \"rescan_id\": \"None\"})\n",
    ")\n",
    "test_dataset = context.dataset.get_cohort_dataset(\n",
    "    'ab300'\n",
    ")\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for subject in train_dataset.all_subjects:\n",
    "    img_aff = subject[\"mean_dwi\"].affine\n",
    "    label_aff = subject['whole_roi'].affine\n",
    "    diff = img_aff - label_aff\n",
    "    if np.any(np.abs(diff) > 1e-6):\n",
    "        print(subject['name'])\n",
    "        print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_dataset_as_nn_unet\n",
    "from data_processing import *\n",
    "\n",
    "save_dataset_as_nn_unet(\n",
    "    context.dataset, \n",
    "    \"X:\\\\Datasets\\\\nnUNet_raw_data_base\\\\nnUNet_raw_data\\\\Task500_DMRI_Hippocampus_Whole\\\\\",\n",
    "    short_name=\"DMRI\", image_names=['mean_dwi', 'md', 'fa'], label_map_name='whole_roi',\n",
    "    train_cohort=RequireAttributes({\"pathologies\": \"None\", \"protocol\": \"cbbrain\", \"rescan_id\": \"None\"}),\n",
    "    test_cohort=None, #\"ab300\",\n",
    "    fix_affine=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context.dataset.all_subjects[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_dataset_as_nn_unet\n",
    "\n",
    "save_dataset_as_nn_unet(\n",
    "    context.dataset, \n",
    "    \"X:\\\\Datasets\\\\nnUNet_raw_data_base\\\\nnUNet_raw_data\\\\Task502_MSSEG2\\\\\",\n",
    "    short_name=\"MSSEG2\", image_names=['flair_time01', 'flair_time02'], label_map_name='ground_truth',\n",
    "    train_cohort = 'all'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = None\n",
    "{1:2, **({} if thing is None else thing), 3:4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RequireAttributes({\"pathologies\": \"None\", \"protocol\": \"cbbrain\", \"rescan_id\": \"None\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torchio as tio\n",
    "\n",
    "subject = context.dataset.all_subjects_map['cbbrain_192']\n",
    "subject = copy.deepcopy(subject)\n",
    "\n",
    "img_aff = subject[\"mean_dwi\"].affine\n",
    "label_aff = subject['whole_roi'].affine\n",
    "print(img_aff - label_aff)\n",
    "\n",
    "subject['whole_roi'].affine = subject['mean_dwi'].affine\n",
    "\n",
    "img_aff = subject[\"mean_dwi\"].affine\n",
    "label_aff = subject['whole_roi'].affine\n",
    "print(img_aff - label_aff)\n",
    "\n",
    "subject['whole_roi'].save('test_label.nii.gz')\n",
    "\n",
    "loaded_label = tio.LabelMap('test_label.nii.gz')\n",
    "print(img_aff - loaded_label.affine)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
