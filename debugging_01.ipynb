{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electric-press",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from utils import load_module\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/diffusion_hippocampus.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI/Subjects/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = config.get_context(device, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/qsm_deep_grey_matter.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/DGM/segmentation_3T_ps18_v3/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = config.get_context(device, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "untransformed_subject =  context.dataset.subjects[0]\n",
    "print(\"Original labels:\")\n",
    "print(untransformed_subject.dgm['label_names'])\n",
    "\n",
    "subject = context.dataset[0]\n",
    "print(\"\\nTransformed labels:\")\n",
    "print(subject.dgm['label_names'])\n",
    "\n",
    "inverse_subject = subject.apply_inverse_transform(warn=False)\n",
    "print(\"\\nInverse transformed labels:\")\n",
    "print(inverse_subject.dgm['label_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in context.dataset[1].items():\n",
    "    print(key, value, type(value))\n",
    "    if isinstance(value, dict):\n",
    "        for key, value2 in value.items():\n",
    "            print(key, value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "           \n",
    "for i in range(2):\n",
    "    loader = sample_data(context.dataloader)\n",
    "    batch = next(loader)\n",
    "    for key, val in batch.items():\n",
    "        print(key, val.shape, val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(20, 20, 20)\n",
    "for y in x.split([3, 2, 5, 10]):\n",
    "    print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "individual-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: efirdc (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">toasty-dream-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/efirdc/my-test-project\" target=\"_blank\">https://wandb.ai/efirdc/my-test-project</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/efirdc/my-test-project/runs/23adh649\" target=\"_blank\">https://wandb.ai/efirdc/my-test-project/runs/23adh649</a><br/>\n",
       "                Run data is saved locally in <code>G:\\Github Repositories\\Segmentation-Pipeline\\wandb\\run-20210614_231834-23adh649</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(23adh649)</h1><iframe src=\"https://wandb.ai/efirdc/my-test-project/runs/23adh649\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2cda25a35e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"my-test-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "virtual-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    log_dict = {\n",
    "        'something': {\n",
    "            foo: {'mean': random.random(), 'std': random.random()}\n",
    "            for foo in \"ABC\"\n",
    "        }\n",
    "    }\n",
    "    wandb.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(10):\n",
    "    evaluation = {}\n",
    "    \n",
    "    for structure in (\"A\", \"B\", \"C\"):\n",
    "        columns = [\"TP\", \"FP\", \"TN\", \"FN\", 'dice', \"jaccard\"]\n",
    "        S = 25\n",
    "        subjects = [f'subject_{i:01}' for i in range(S)]\n",
    "\n",
    "        df = pd.DataFrame(data=np.random.randint(50, 100, size=(S, 4)), columns=[\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "        df.insert(loc=0, column='Subject', value=subjects)\n",
    "\n",
    "        TP, FP, TN, FN = df[\"TP\"], df[\"FP\"], df[\"TN\"], df[\"FN\"]\n",
    "\n",
    "        df['dice'] = 2 * TP / (2 * TP + FP + FN)\n",
    "        df['jaccard'] = TP / (TP + FP + FN)\n",
    "        evaluation[f\"Structure {structure}\"] = wandb.Table(dataframe=df)\n",
    "        \n",
    "    wandb.log({f'Segmentation Evaluation': evaluation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'X:\\Datasets\\Diffusion_MRI\\Attributes\\demographics.xlsx'\n",
    "df = pd.read_excel(file_path, index_col=0)\n",
    "#subject_col = df.columns[0]\n",
    "data = df.to_dict(orient='dict')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "print(pathlib.Path('yourPath.example').suffix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'X:\\Datasets\\DGM\\subject_attributes\\dgm_label_names.json'\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'X:\\Datasets\\DGM\\subject_attributes\\dgm_label_names.csv'\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "data = df.to_dict()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import is_sequence\n",
    "\n",
    "def test_func(*args):\n",
    "    if is_sequence(args) and len(args) == 1 and is_sequence(args[0]):\n",
    "        args = args[0]\n",
    "    print(args)\n",
    "    \n",
    "test_func(\"a\", \"b\", \"c\")\n",
    "test_func((\"a\", \"b\", \"c\"))\n",
    "test_func([\"a\", \"b\", \"c\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 0, 1]).bool()\n",
    "b = torch.tensor([1, 1, 0]).bool()\n",
    "a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "revised-studio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A':        subject    FP   TP      dice\n",
       " 0   subject_00  1246  338  0.210986\n",
       " 1   subject_01  1233  308  0.192801\n",
       " 2   subject_02  1358  309  0.191747\n",
       " 3   subject_03  1329  315  0.194926\n",
       " 4   subject_04  1287  313  0.197601\n",
       " 5   subject_05  1245  327  0.205725\n",
       " 6   subject_06  1284  359  0.218702\n",
       " 7   subject_07  1272  302  0.189460\n",
       " 8   subject_08  1280  299  0.188346\n",
       " 9   subject_09  1324  363  0.219005\n",
       " 10  subject_10  1194  336  0.217546\n",
       " 11  subject_11  1268  328  0.203790\n",
       " 12  subject_12  1307  316  0.193984\n",
       " 13  subject_13  1304  290  0.187036\n",
       " 14  subject_14  1256  343  0.213508\n",
       " 15  subject_15  1268  317  0.195739\n",
       " 16  subject_16  1388  325  0.198473\n",
       " 17  subject_17  1254  290  0.187581\n",
       " 18  subject_18  1236  325  0.206088\n",
       " 19  subject_19  1296  328  0.203663,\n",
       " 'B':        subject    FP   TP      dice\n",
       " 0   subject_00  1289  350  0.212572\n",
       " 1   subject_01  1340  313  0.194289\n",
       " 2   subject_02  1252  315  0.196998\n",
       " 3   subject_03  1274  301  0.190145\n",
       " 4   subject_04  1276  292  0.184111\n",
       " 5   subject_05  1339  343  0.208764\n",
       " 6   subject_06  1243  309  0.199871\n",
       " 7   subject_07  1269  302  0.187753\n",
       " 8   subject_08  1291  311  0.196773\n",
       " 9   subject_09  1239  353  0.220556\n",
       " 10  subject_10  1279  347  0.216132\n",
       " 11  subject_11  1259  303  0.190806\n",
       " 12  subject_12  1275  307  0.193874\n",
       " 13  subject_13  1289  327  0.200184\n",
       " 14  subject_14  1233  299  0.191790\n",
       " 15  subject_15  1283  292  0.186940\n",
       " 16  subject_16  1267  320  0.199439\n",
       " 17  subject_17  1270  325  0.202808\n",
       " 18  subject_18  1297  305  0.190268\n",
       " 19  subject_19  1286  358  0.219767,\n",
       " 'C':        subject    FP   TP      dice\n",
       " 0   subject_00  1331  296  0.185000\n",
       " 1   subject_01  1354  315  0.196937\n",
       " 2   subject_02  1300  342  0.212225\n",
       " 3   subject_03  1271  322  0.201628\n",
       " 4   subject_04  1280  326  0.202296\n",
       " 5   subject_05  1270  313  0.194048\n",
       " 6   subject_06  1306  335  0.204956\n",
       " 7   subject_07  1357  333  0.203297\n",
       " 8   subject_08  1292  332  0.203869\n",
       " 9   subject_09  1233  309  0.197570\n",
       " 10  subject_10  1299  337  0.207896\n",
       " 11  subject_11  1290  321  0.196872\n",
       " 12  subject_12  1320  338  0.207680\n",
       " 13  subject_13  1250  324  0.202627\n",
       " 14  subject_14  1307  345  0.209726\n",
       " 15  subject_15  1288  330  0.202206\n",
       " 16  subject_16  1248  324  0.202121\n",
       " 17  subject_17  1348  339  0.205330\n",
       " 18  subject_18  1289  349  0.216636\n",
       " 19  subject_19  1198  315  0.199810,\n",
       " 'D':        subject    FP   TP      dice\n",
       " 0   subject_00  1241  314  0.201347\n",
       " 1   subject_01  1228  311  0.199936\n",
       " 2   subject_02  1295  302  0.188338\n",
       " 3   subject_03  1209  291  0.186061\n",
       " 4   subject_04  1285  335  0.208593\n",
       " 5   subject_05  1244  306  0.198058\n",
       " 6   subject_06  1257  322  0.203283\n",
       " 7   subject_07  1304  305  0.193160\n",
       " 8   subject_08  1256  316  0.203085\n",
       " 9   subject_09  1276  328  0.205321\n",
       " 10  subject_10  1303  307  0.191158\n",
       " 11  subject_11  1297  331  0.204890\n",
       " 12  subject_12  1297  291  0.186300\n",
       " 13  subject_13  1275  331  0.203692\n",
       " 14  subject_14  1280  311  0.195107\n",
       " 15  subject_15  1281  310  0.197389\n",
       " 16  subject_16  1225  335  0.211423\n",
       " 17  subject_17  1280  336  0.208760\n",
       " 18  subject_18  1289  324  0.199692\n",
       " 19  subject_19  1296  312  0.195918,\n",
       " 'E':        subject    FP   TP      dice\n",
       " 0   subject_00  1296  299  0.187814\n",
       " 1   subject_01  1260  338  0.206538\n",
       " 2   subject_02  1218  309  0.196253\n",
       " 3   subject_03  1353  335  0.204268\n",
       " 4   subject_04  1297  309  0.191628\n",
       " 5   subject_05  1288  325  0.201926\n",
       " 6   subject_06  1282  303  0.190088\n",
       " 7   subject_07  1273  283  0.179057\n",
       " 8   subject_08  1301  322  0.195448\n",
       " 9   subject_09  1289  286  0.180955\n",
       " 10  subject_10  1296  302  0.186075\n",
       " 11  subject_11  1299  304  0.195310\n",
       " 12  subject_12  1259  290  0.181477\n",
       " 13  subject_13  1309  301  0.189070\n",
       " 14  subject_14  1300  326  0.204325\n",
       " 15  subject_15  1274  357  0.220916\n",
       " 16  subject_16  1271  297  0.189112\n",
       " 17  subject_17  1231  327  0.205531\n",
       " 18  subject_18  1290  296  0.186574\n",
       " 19  subject_19  1290  321  0.201697,\n",
       " 'summary_stats':   label_name      FP.mean     FP.std     TP.mean     TP.std  dice.mean  dice.std\n",
       " 0          A  1281.449951  45.419071  321.549988  19.982822   0.200835  0.010719\n",
       " 1          B  1277.500000  27.649117  318.600006  20.999750   0.199192  0.011026\n",
       " 2          C  1291.550049  40.493633  327.250000  13.337225   0.202636  0.006850\n",
       " 3          D  1270.900024  28.421452  315.899994  13.897747   0.199076  0.007420\n",
       " 4          E  1283.800049  28.548389  311.500000  19.236752   0.194703  0.010571}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchio as tio\n",
    "import torch\n",
    "from evaluation import SegmentationEvaluator\n",
    "\n",
    "label_values = {letter: val for val, letter in enumerate(\"ABCDE\")}\n",
    "print(label_values)\n",
    "\n",
    "subjects = [\n",
    "    tio.Subject({\n",
    "        'name': f'subject_{i:02}',\n",
    "        'pred': tio.LabelMap(\n",
    "            tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "            label_values=label_values\n",
    "        ),\n",
    "        'target': tio.LabelMap(\n",
    "            tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "            label_values=label_values\n",
    "        ),                  \n",
    "    })\n",
    "    for i in range(20)\n",
    "]\n",
    "\n",
    "seg_evaluator = SegmentationEvaluator(\n",
    "    name=\"test_evaluator\", outputs=['FP', 'TP', 'dice'], prediction_label_name='pred', target_label_name='target'\n",
    ")\n",
    "\n",
    "seg_evaluator(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = tio.LabelMap(\n",
    "    tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "    label_values=label_values\n",
    ")\n",
    "\n",
    "tio.OneHot()(label_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
