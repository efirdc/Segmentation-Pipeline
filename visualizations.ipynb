{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchio as tio\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from context import Context\n",
    "from evaluators import *\n",
    "from utils import slice_volume, load_module\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"X:/Checkpoints/Diffusion_MRI/dmri-hippo-northern-pond-67/checkpoints/iter{100:08}.pt\"\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "from configs.diffusion_hippocampus import *\n",
    "\n",
    "context = Context(device, file_name=file_name, variables=variables, globals=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/msseg2.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/MSSEG2_processed/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = config.get_context(device, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = context.dataset.get_cohort_dataset('training')\n",
    "validation_dataset = context.dataset.get_cohort_dataset('validation')\n",
    "print(len(training_dataset))\n",
    "[subject['name'] for subject in training_dataset.subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3e0b54d3f04b5196d7b3656fb15ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='name', options=('013', '015', '016', '018', '019', '020', '021', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = context.dataset\n",
    "all_subject_names = list(dataset.all_subjects_map.keys())\n",
    "\n",
    "def vis_subject(subject):\n",
    "    images = {key: val for key, val in subject.items() if isinstance(val, tio.ScalarImage)}\n",
    "    label_maps = {key: val for key, val in subject.items() if isinstance(val, tio.LabelMap)}\n",
    "    \n",
    "    @interact(image_name=images.keys(), label_map_name=label_maps.keys(), plane=['Axial', 'Coronal', 'Saggital'])\n",
    "    def select_images(image_name, label_map_name, plane):\n",
    "        label_map_name = 'y'\n",
    "        image = images[image_name]\n",
    "        label_map = label_maps[label_map_name]\n",
    "        W, H, D = image.spatial_shape\n",
    "        num_slices = {'Axial': D, 'Coronal': H, 'Saggital': W}[plane]\n",
    "        \n",
    "        @interact(slice_id=(0, num_slices-1))\n",
    "        def select_slice(slice_id):\n",
    "            evaluator = ContourImageEvaluator(\n",
    "                plane=plane, image_name=image_name, \n",
    "                target_label_map_name=label_map_name, \n",
    "                prediction_label_map_name=None, \n",
    "                slice_id=slice_id, legend=True, ncol=1\n",
    "            )\n",
    "            evaluation = evaluator([subject])\n",
    "            pil_image = evaluation['image']\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(pil_image, aspect='equal')\n",
    "            plt.show()\n",
    "            plt.close(fig)\n",
    "            \n",
    "def vis_features(x):\n",
    "    N, C, W, H, D = x.shape\n",
    "    \n",
    "    @interact(i=(0, N-1), c=(0, C-1), d=(0, D-1))\n",
    "    def plot_feature_map(i, c, d):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(x[i, c, :, :, d].cpu(), cmap=\"gray\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "\n",
    "def vis_model(subject):\n",
    "    X = subject['X']['data'].unsqueeze(0).to(device)\n",
    "    modules = list(context.model.named_modules())\n",
    "    \n",
    "    @interact(module=modules[1:])\n",
    "    def select_module(module):\n",
    "    \n",
    "        def forward_module_hook(module, x_in, x_out):\n",
    "            vis_features(x_out.cpu())\n",
    "            \n",
    "        hook_handle = module.register_forward_hook(forward_module_hook)\n",
    "        with torch.no_grad():\n",
    "            context.model(X)\n",
    "        hook_handle.remove()\n",
    "\n",
    "\n",
    "@interact(name=all_subject_names)\n",
    "def vis(name):\n",
    "    subject = context.dataset[name]\n",
    "    vis_subject(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in context.dataset:\n",
    "    time01 = subject['flair_time01'].data\n",
    "    time01 = subject['flair_time01'].data\n",
    "    print(subject['name'], subject['flair_time01'], time01.mean(), time01.std(), time01.min(), time01.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in context.dataset:\n",
    "    print(subject['name'], subject['flair_time01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = context.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask = subject['brain_mask'].data.bool()[0]\n",
    "W, H, D = mask.shape\n",
    "W_where, H_where, D_where = np.where(mask)\n",
    "cropping = (\n",
    "    W_where.min(), W - W_where.max(), \n",
    "    H_where.min(), H - H_where.max(), \n",
    "    D_where.min(), D - D_where.max()\n",
    ")\n",
    "cropping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
