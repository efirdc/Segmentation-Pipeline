{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informed-antique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from utils import load_module\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handy-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/diffusion_hippocampus.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = config.get_context(device, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/qsm_deep_grey_matter.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/DGM/segmentation_3T_ps18_v3/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = config.get_context(device, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasd_dataset = context.dataset.get_cohort_dataset('fasd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasd_dataset.preload_and_transform_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "synthetic-tablet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels:\n",
      "{'left_whole': 1, 'right_whole': 2}\n",
      "\n",
      "Transformed labels:\n",
      "{'left_whole': 1, 'right_whole': 1}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The number of input channels was expected to be 2, but it is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f6b0ff862248>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label_values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0minverse_subject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_inverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nInverse transformed labels:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minverse_subject\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label_values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cefir\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchio\\data\\subject.py\u001b[0m in \u001b[0;36mapply_inverse_transform\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \"\"\"\n\u001b[0;32m    188\u001b[0m         \u001b[0minverse_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_inverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[0mtransformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cefir\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchio\\transforms\\transform.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0msubject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages_to_keep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cefir\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchio\\transforms\\augmentation\\composition.py\u001b[0m in \u001b[0;36mapply_transform\u001b[1;34m(self, subject)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSubject\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSubject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0msubject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msubject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cefir\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchio\\transforms\\transform.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0msubject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages_to_keep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Github Repositories\\Segmentation-Pipeline\\transforms\\custom_label_transforms.py\u001b[0m in \u001b[0;36mapply_transform\u001b[1;34m(self, subject)\u001b[0m\n\u001b[0;32m    241\u001b[0m                     \u001b[1;34mf' but it is {num_channels}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m                 )\n\u001b[1;32m--> 243\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The number of input channels was expected to be 2, but it is 1"
     ]
    }
   ],
   "source": [
    "untransformed_subject = context.dataset.subjects[0]\n",
    "print(\"Original labels:\")\n",
    "print(untransformed_subject['whole_roi']['label_values'])\n",
    "\n",
    "subject = context.dataset[0]\n",
    "print(\"\\nTransformed labels:\")\n",
    "print(subject['y']['label_values'])\n",
    "\n",
    "inverse_subject = subject.apply_inverse_transform(warn=False)\n",
    "print(\"\\nInverse transformed labels:\")\n",
    "print(inverse_subject['y']['label_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in context.dataset[1].items():\n",
    "    print(key, value, type(value))\n",
    "    if isinstance(value, dict):\n",
    "        for key, value2 in value.items():\n",
    "            print(key, value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "           \n",
    "for i in range(2):\n",
    "    loader = sample_data(context.dataloader)\n",
    "    batch = next(loader)\n",
    "    for key, val in batch.items():\n",
    "        print(key, val.shape, val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(20, 20, 20)\n",
    "for y in x.split([3, 2, 5, 10]):\n",
    "    print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"test-project-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    log_dict = {\n",
    "        'something': {\n",
    "            foo: {'mean': random.random(), 'std': random.random()}\n",
    "            for foo in \"ABC\"\n",
    "        }\n",
    "    }\n",
    "    wandb.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(10):\n",
    "    evaluation = {}\n",
    "    \n",
    "    for structure in (\"A\", \"B\", \"C\"):\n",
    "        columns = [\"TP\", \"FP\", \"TN\", \"FN\", 'dice', \"jaccard\"]\n",
    "        S = 25\n",
    "        subjects = [f'subject_{i:01}' for i in range(S)]\n",
    "\n",
    "        df = pd.DataFrame(data=np.random.randint(50, 100, size=(S, 4)), columns=[\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "        df.insert(loc=0, column='Subject', value=subjects)\n",
    "\n",
    "        TP, FP, TN, FN = df[\"TP\"], df[\"FP\"], df[\"TN\"], df[\"FN\"]\n",
    "\n",
    "        df['dice'] = 2 * TP / (2 * TP + FP + FN)\n",
    "        df['jaccard'] = TP / (TP + FP + FN)\n",
    "        evaluation[f\"Structure {structure}\"] = wandb.Table(dataframe=df)\n",
    "        \n",
    "    wandb.log({f'Segmentation Evaluation': evaluation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'X:\\Datasets\\Diffusion_MRI\\Attributes\\demographics.xlsx'\n",
    "df = pd.read_excel(file_path, index_col=0)\n",
    "#subject_col = df.columns[0]\n",
    "data = df.to_dict(orient='dict')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "print(pathlib.Path('yourPath.example').suffix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'X:\\Datasets\\DGM\\subject_attributes\\dgm_label_names.json'\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'X:\\Datasets\\DGM\\subject_attributes\\dgm_label_names.csv'\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "data = df.to_dict()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import is_sequence\n",
    "\n",
    "def test_func(*args):\n",
    "    if is_sequence(args) and len(args) == 1 and is_sequence(args[0]):\n",
    "        args = args[0]\n",
    "    print(args)\n",
    "    \n",
    "test_func(\"a\", \"b\", \"c\")\n",
    "test_func((\"a\", \"b\", \"c\"))\n",
    "test_func([\"a\", \"b\", \"c\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 0, 1]).bool()\n",
    "b = torch.tensor([1, 1, 0]).bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "import torch\n",
    "from evaluators import SegmentationEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "def pd_to_dict(elem):\n",
    "    if isinstance(elem, dict):\n",
    "        return {\n",
    "            key: pd_to_wandb(val)\n",
    "            for key, val in elem.items()\n",
    "        }\n",
    "    elif isinstance(elem, pd.DataFrame):\n",
    "        return elem.to_dict()\n",
    "    return elem\n",
    "\n",
    "def pd_to_wandb(elem):\n",
    "    if isinstance(elem, dict):\n",
    "        return {\n",
    "            key: pd_to_wandb(val)\n",
    "            for key, val in elem.items()\n",
    "        }\n",
    "    elif isinstance(elem, pd.DataFrame):\n",
    "        return wandb.Table(dataframe=elem)\n",
    "    return elem\n",
    "\n",
    "wandb.init(project=\"test-project-4\")\n",
    "for i in range(10):\n",
    "    label_values = {letter: val for val, letter in enumerate(\"ABCDE\")}\n",
    "\n",
    "    subjects = [\n",
    "        tio.Subject({\n",
    "            'name': f'subject_{i:02}',\n",
    "            'pred': tio.LabelMap(\n",
    "                tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "                label_values=label_values\n",
    "            ),\n",
    "            'target': tio.LabelMap(\n",
    "                tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "                label_values=label_values\n",
    "            ),\n",
    "        })\n",
    "        for i in range(20)\n",
    "    ]\n",
    "\n",
    "    seg_evaluator = SegmentationEvaluator(\n",
    "        prediction_label_name='pred', target_label_name='target', stats_to_output=['FP', 'TP', 'dice'], \n",
    "    )\n",
    "\n",
    "    log_dict = seg_evaluator(subjects)\n",
    "    wandb.log(pd_to_wandb(log_dict))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = tio.LabelMap(\n",
    "    tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "    label_values=label_values\n",
    ")\n",
    "\n",
    "tio.OneHot()(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10).unsqueeze(1)\n",
    "mask = torch.tensor([0, 1, 1, 0]).bool().unsqueeze(0)\n",
    "x, mask = torch.broadcast_tensors(x, mask)\n",
    "\n",
    "print(x.shape, mask.shape)\n",
    "\n",
    "x[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluators import VolumeStatsEvaluator\n",
    "import pandas as pd\n",
    "import torchio as tio\n",
    "\n",
    "\n",
    "label_values = {f'label_{letter}': (val + 1) for val, letter in enumerate(\"abcde\")}\n",
    "\n",
    "subjects = [\n",
    "    tio.Subject({\n",
    "        'name': f'subject_{i:02}',\n",
    "        'label': tio.LabelMap(\n",
    "            tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "            label_values=label_values\n",
    "        ),\n",
    "        'md': tio.ScalarImage(\n",
    "            tensor=torch.randn(size=(1, 20, 20, 20)) * 2 + 1,\n",
    "        ),\n",
    "        'fa': tio.ScalarImage(\n",
    "            tensor=torch.randn(size=(1, 20, 20, 20)) * 0.5 - 3,\n",
    "        ),\n",
    "    })\n",
    "    for i in range(20)\n",
    "]\n",
    "\n",
    "volume_stats_eval = VolumeStatsEvaluator(\n",
    "    label_map_name='label', image_names=['md', 'fa']\n",
    ")\n",
    "\n",
    "volume_stats_eval(subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "def merge_dicts(a, b):\n",
    "    merged_dict = {}\n",
    "    for key in a.keys():\n",
    "        if key in b:\n",
    "            merged_dict[key] = merge_dicts(a[key], b[key])\n",
    "        else:\n",
    "            merged_dict[key] = a[key]\n",
    "    for key in b.keys():\n",
    "        if key not in a:\n",
    "            merged_dict[key] = b[key]\n",
    "    return merged_dict\n",
    "\n",
    "dict1 = {'mean': {'hippo': {'md': {'subject_1': 1}}}}\n",
    "dict2 = {'mean': {'hippo': {'md': {'subject_2': 2}}}}\n",
    "dict3 = {'mean': {'hippo': {'fa': {'subject_1': 3}}}}\n",
    "dict4 = {'mean': {'hippo': {'fa': {'subject_2': 4}}}}\n",
    "\n",
    "out_dict = merge_dicts(dict1, dict2)\n",
    "\n",
    "out_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
