{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a4d843-571a-4f93-a161-f1479297d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "import torch\n",
    "from segmentation_pipeline import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc266f1-7c79-421b-9f8c-f50ee88a9402",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"../configs/diffusion_hippocampus.py\")\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI_cropped/\", CHECKPOINTS_PATH=\"X:/Checkpoints/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19e6ea-d8f1-4f9b-bdc8-3a3b6f7a7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torchio as tio\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "out_path = Path(\"X:\\\\Datasets\\\\Diffusion_MRI_cropped\\\\\")\n",
    "\n",
    "crop_transform = tio.CropOrPad((96, 88, 24), padding_mode='minimum', mask_name='whole_roi_union')\n",
    "\n",
    "for i, subject in enumerate(context.dataset.subjects):\n",
    "    subject = copy.deepcopy(subject)\n",
    "    subject.load()\n",
    "    subject = crop_transform(subject)\n",
    "    \n",
    "    subject_path = Path(subject.folder)\n",
    "    out_subject_path = out_path / \"subjects\" / subject['name']\n",
    "    out_subject_path.mkdir(exist_ok=True)\n",
    "\n",
    "    for image_name, image in subject.get_images_dict(intensity_only=False).items():\n",
    "        if \"uniform\" in image and image['uniform']:\n",
    "            continue\n",
    "        image.save(out_subject_path / f\"{image_name}.nii.gz\")\n",
    "    shutil.copy(subject_path / \"attributes.json\", out_subject_path / \"attributes.json\")\n",
    "\n",
    "    if i == 0:\n",
    "        uniform_path = out_path / \"atlas\"\n",
    "        uniform_path.mkdir(exist_ok=True)\n",
    "        for image_name, image in subject.get_images_dict(intensity_only=False).items():\n",
    "            if \"uniform\" not in image or not image['uniform']:\n",
    "                continue\n",
    "            image.save(uniform_path / f\"{image_name}.nii.gz\")\n",
    "            \n",
    "    if i % 10 == 0:\n",
    "        print(f\"Saved subject {subject.name} {i}/{len(context.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bae676-d05f-4e22-afe6-cb6006cc810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = context.dataset.subjects[0].shape\n",
    "all_hippo = torch.zeros(size=shape, dtype=torch.int64)\n",
    "N = 0\n",
    "\n",
    "for subject in context.dataset.subjects:\n",
    "    if 'whole_roi' in subject:\n",
    "        N += 1\n",
    "        all_hippo += (subject['whole_roi'].data > 0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60a0ce-3e65-4e09-94cc-fcf722998bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "from pathlib import Path\n",
    "\n",
    "whole_roi_union = tio.LabelMap(tensor=(all_hippo != 0))\n",
    "whole_roi_mean = tio.LabelMap(tensor=(all_hippo / N) > 0.5)\n",
    "\n",
    "whole_roi_union.save(Path(context.dataset.root) / \"atlas\" / \"whole_roi_union.nii.gz\")\n",
    "whole_roi_mean.save(Path(context.dataset.root) / \"atlas\" / \"whole_roi_mean.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a686f7-9ddc-4a82-b905-fce4330b70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_pipeline.data_processing.dataset_fingerprint import *\n",
    "\n",
    "get_bounds(whole_roi_union['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239f2f2-f325-46bc-8b91-e7275343541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_fingerprints, summary_fingerprint = get_dataset_fingerprint(\n",
    "    context.dataset,\n",
    "    transform=EnforceConsistentAffine(),\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097f485-2d79-433e-9142-37c1f8e862c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "with (Path(context.dataset.root) / \"fingerprint\" / \"subject_fingerprints.json\").open() as f:\n",
    "    subject_fingerprints = json.load(f)\n",
    "    \n",
    "with (Path(context.dataset.root) / \"fingerprint\" / \"fingerprint.json\").open() as f:\n",
    "    fingerprint = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aec411-0a48-40bc-9511-aecd0d72bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(fingerprint['label_crop']['whole_roi']['all'])\n",
    "\n",
    "crop_mean = np.array(fingerprint['label_crop']['whole_roi']['all']['median'])\n",
    "crop_std = np.array(fingerprint['label_crop']['whole_roi']['all']['std'])\n",
    "\n",
    "print(crop_mean)\n",
    "print(crop_std)\n",
    "\n",
    "for subject_name, fp in subject_fingerprints.items():\n",
    "    try:\n",
    "        subject_crop = np.array(fp['label_crop']['whole_roi']['all'])\n",
    "    except:\n",
    "        continue\n",
    "    diff = np.abs(crop_mean - subject_crop)\n",
    "    if np.any(diff > 3 * crop_std):\n",
    "        print(subject_name, subject_crop, diff / crop_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129318c6-c68e-42b1-b65c-1b895818b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torchio as tio\n",
    "import shutil\n",
    "\n",
    "dataset = context.dataset.get_cohort_dataset(\"cbbrain\")\n",
    "subject_paths = {subject['subject_id']: subject['folder'] for subject in dataset.subjects}\n",
    "\n",
    "def get_subject_id(file_path):\n",
    "    out = file_path.stem\n",
    "    out = out.split(\".\")[0]\n",
    "    out = out.split(\"_\")[2]\n",
    "    out = int(out)\n",
    "    return out\n",
    "\n",
    "\"\"\"\n",
    "full_dwi_path = Path(\"X:\\\\Datasets\\\\Diffusion_MRI_extra\\\\Diffusion_MRI_old\\\\Cb_Brain_n153\\\\Full\")\n",
    "for full_dwi_path in full_dwi_path.iterdir():\n",
    "    subject_id = get_subject_id(full_dwi_path)\n",
    "    out_path = Path(subject_paths[subject_id])\n",
    "    \n",
    "    full_dwi = tio.ScalarImage(full_dwi_path, channels_last=True)\n",
    "    full_dwi.load()\n",
    "    print(f\"Saving {full_dwi_path} to {out_path}\")\n",
    "    full_dwi.save(out_path / \"full_dwi.nii.gz\")\n",
    "\"\"\"\n",
    "\n",
    "bvec_folder_path = Path(\"X:\\\\Datasets\\\\Diffusion_MRI_extra\\\\Diffusion_MRI_old\\\\Cb_Brain_n153\\\\Gradient_Info\")\n",
    "for bvec_path in bvec_folder_path.iterdir():\n",
    "    subject_id = get_subject_id(bvec_path)\n",
    "    out_path = Path(subject_paths[subject_id])\n",
    "    shutil.copyfile(bvec_path, out_path / \"full_dwi_grad.b\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c8b08-1bc5-44f7-84f1-f47df7228551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "dest_path = Path(\"X:\\\\Predictions\\\\Diffusion_MRI\\\\isbi_models\")\n",
    "\n",
    "for subject in context.dataset.subjects:\n",
    "    subject_path = Path(subject['folder'])\n",
    "    \n",
    "    dest_subject_path = dest_path / subject['name']\n",
    "    dest_subject_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    for subject_file in subject_path.iterdir():\n",
    "        if \"pred\" in subject_file.name:\n",
    "            shutil.move(subject_file, dest_subject_path / subject_file.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
