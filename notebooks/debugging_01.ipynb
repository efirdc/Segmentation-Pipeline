{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "import torch\n",
    "from segmentation_pipeline import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d8bbf892-94a3-4345-aec3-ca571aacaa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5277058988770118 4.6075944008792025\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222a656-6bfe-4f64-abcc-2b2cb02b4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchgenerators.utilities.file_and_folder_operations import load_pickle, save_pickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "root = Path(\"X:/Datasets/nnUNet_raw_data_base/nnUNet_raw_data/Task501_DMRI_Hippocampus_Whole/\")\n",
    "\n",
    "root = Path(\"X:/Datasets/nnUNet_preprocessed/Task501_DMRI_Hippocampus_Whole/\")\n",
    "dataset_properties = load_pickle(root / \"nnUNetPlansv2.1_plans_3D.pkl\")\n",
    "dataset_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e12ef5-9de8-4bb2-a60f-dc0edf4b45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "\n",
    "from segmentation_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b2b96-f025-4c64-b1e2-cd76037d961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_as_nn_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17ed60-f829-44cb-b473-260137189e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"../configs/diffusion_hippocampus.py\")\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ae96f-3358-4ebb-96f5-62367bb94fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in context.dataset.cohorts.keys():\n",
    "    dataset = context.dataset.get_cohort_dataset(name)\n",
    "    print(name, len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac7a25-e36f-40dd-9069-897cf7fd6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_labels = [\"whole_roi\"]\n",
    "cbbrain_dataset = context.dataset.get_cohort_dataset(ComposeFilters([\n",
    "    RequireAttributes(output_labels),\n",
    "    RequireAttributes({\"pathologies\": \"None\", \"rescan_id\": \"None\"}),\n",
    "    RequireAttributes({\"protocol\": \"cbbrain\"}),\n",
    "]))\n",
    "ab300_unlabeled_dataset = context.dataset.get_cohort_dataset(ComposeFilters([\n",
    "    ForbidAttributes(output_labels),\n",
    "    RequireAttributes({\"pathologies\": \"None\", \"rescan_id\": \"None\"}),\n",
    "    RequireAttributes({\"protocol\": \"ab300\"})\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fceb27-bf8e-4268-ae1c-5450e54a94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filter = StratifiedFilter(size=53, continuous_attributes=['age'], discrete_attributes=['gender'])\n",
    "cbbrain_test = cbbrain_dataset.get_cohort_dataset(test_filter)\n",
    "cbbrain_\n",
    "len(cbbrain_test.subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dc4b3-d8d0-41ae-b751-5a94262ab687",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2, 2, 9)\n",
    "print(x.shape)\n",
    "key = (slice(0, 0, 0), 0, 2)\n",
    "x[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896fba2-0982-499d-9ffb-4576ea4b8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tensor = LabeledTensor(\n",
    "    dim_names=['subject', 'label', 'stat'],\n",
    "    dim_keys=[\n",
    "        [f'subject_{i}' for i in range(10)],\n",
    "        [f'label_{l}' for l in \"ABCD\"],\n",
    "        [stat for stat in (\"dice\", 'fp', 'tp')]\n",
    "    ]\n",
    ")\n",
    "\n",
    "labeled_tensor.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628cb69e-e1f3-4dcb-8288-4aff5ca5c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from inspect import signature\n",
    "from utils import Config\n",
    "\n",
    "class Baz(Config):\n",
    "    def __init__(self, param1: int, param2: str = \"asdf\"):\n",
    "        self.param1 = param1\n",
    "        self.param2 = param2\n",
    "        \n",
    "class Bar(Config):\n",
    "    def __init__(self, param1: str, param2: Baz):\n",
    "        self.param1 = param1\n",
    "        self.param2 = param2\n",
    "\n",
    "class Foo(Config):\n",
    "    def __init__(self, param1: str, param2: int, param3: Bar):\n",
    "        self.param1 = param1\n",
    "        self.param2 = param2\n",
    "        self.param3 = param3\n",
    "        \n",
    "\n",
    "foo = Foo(\"apple\", 10, Bar(\"orange\", Baz(5)))\n",
    "print(foo.get_config())\n",
    "print(foo.get_flattened_nested_config())\n",
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations([0, 1, 2], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0, 1, 0, 1])\n",
    "y = torch.tensor([1, 0, 1, 0])\n",
    "\n",
    "x[None, :] + y[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "P, T = 5, 7\n",
    "prediction = torch.randint(P, size=(1, 5, 5, 5))\n",
    "target = torch.randint(T, size=(1, 1, 5, 5, 5))\n",
    "\n",
    "prediction == torch.arange(1, P).reshape(P - 1, 1, 1, 1, 1)\n",
    "target == torch.arange(1, P).reshape(P - 1, 1, 1, 1, 1)\n",
    "\n",
    "P_labels = torch.tensor([i // T for i in range(P * T)]).reshape(P * T, 1, 1, 1)\n",
    "T_labels = torch.tensor([i % P for i in range(P * T)]).reshape(P * T, 1, 1, 1)\n",
    "\n",
    "torch.cat((prediction, target)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, permutations, product\n",
    "\n",
    "label_combinations = torch.tensor(list(product(range(P), range(T)))).T\n",
    "label_combinations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-model",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "x = xr.DataArray(\n",
    "    dims=['subject', 'structure', 'stat'],\n",
    "    coords={\n",
    "        \"subject\": [f\"subject_{i:02}\" for i in range(10)],\n",
    "        \"structure\": ['head', 'body', 'tail'],\n",
    "        \"stat\": [\"dice\", \"FP\", \"TP\"]\n",
    "    }\n",
    ")\n",
    "x.data = torch.randn(x.data.shape)\n",
    "x.loc['subject_01', 'head', 'FP'] = 1000\n",
    "\n",
    "x = x.stack(desired=['structure', 'stat'])\n",
    "\n",
    "df = x.transpose().to_dataframe(name='what')\n",
    "df['what']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"test-project-2\")\n",
    "\n",
    "wandb.log({'table': wandb.Table(dataframe=df['what'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_processing import sort_by_size\n",
    "from skimage.morphology import label, remove_small_holes, dilation\n",
    "\n",
    "\n",
    "for subject in context.dataset:\n",
    "    lesion_data = (subject['y'].data[1] > 0.5).numpy()\n",
    "    img_comp = label(lesion_data)\n",
    "    _, _, counts = sort_by_size(img_comp)\n",
    "    \n",
    "    print(f'subject={subject[\"name\"]}, lesions={len(counts)}, volumes={[v for v in counts]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch_context import TorchContext\n",
    "from pathlib import Path\n",
    "from models import EnsembleOrientations, EnsembleModels\n",
    "\n",
    "cv_path = \"X:\\\\Checkpoints\\\\MSSEG2\\\\cross_validation_01\\\\ensemble_01\\\\\"\n",
    "\n",
    "ensemble_path = Path(cv_path)\n",
    "models = []\n",
    "for file_path in ensemble_path.iterdir():\n",
    "    context = TorchContext(\n",
    "        device, file_path=file_path, variables=dict(DATASET_PATH='X:\\\\Datasets\\\\MSSEG2_processed')\n",
    "    )\n",
    "    context.keep_components(('model', 'dataset'))\n",
    "    context.init_components()\n",
    "\n",
    "    models.append(context.model)\n",
    "\n",
    "model = EnsembleModels(models, strategy='mean')\n",
    "model = EnsembleOrientations(model, strategy='mean')\n",
    "context.model = model\n",
    "dataset = context.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms import *\n",
    "import torchio as tio\n",
    "\n",
    "subject = dataset.subjects[3]\n",
    "transforms = tio.Compose([\n",
    "    SetDataType(torch.float),\n",
    "    EnforceConsistentAffine(source_image_name='flair_time01'),\n",
    "    TargetResample(target_spacing=1, tolerance=0.11),\n",
    "    CropToMask('brain_mask'),\n",
    "    MinSizePad(96),\n",
    "    tio.RescaleIntensity((0, 1.), (0.05, 99.5)),\n",
    "    ConcatenateImages(image_names=[\"flair_time01\", \"flair_time02\"], image_channels=[1, 1], new_image_name=\"X\"),\n",
    "    RenameProperty(old_name='ground_truth', new_name='y'),\n",
    "    CustomOneHot(include=\"y\"),\n",
    "])\n",
    "\n",
    "subject = transforms(subject)\n",
    "\n",
    "t1 = subject['flair_time01'].data\n",
    "t2 = subject['flair_time02'].data\n",
    "for img_name, img in subject.get_images_dict().items():\n",
    "    data = img['data']\n",
    "    print(img_name, data.min(), data.max(), data.isnan().sum(), data.isinf().sum())\n",
    "#tio.RescaleIntensity((-1, 1.), (0.05, 99.5))(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "\n",
    "for subject in dataset:\n",
    "    grid_sampler = tio.GridSampler(subject,\n",
    "                                   patch_size=96,\n",
    "                                   patch_overlap=32,\n",
    "                                   padding_mode='edge')\n",
    "    print(len(grid_sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "from ipywidgets import interact\n",
    "from transforms import *\n",
    "from models import *\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subject = context.dataset.subjects[12]\n",
    "spatial_augmentations = tio.Compose([\n",
    "    RandomPermuteDimensions(),\n",
    "    tio.RandomFlip(axes=(0, 1, 2)),\n",
    "    tio.OneOf({\n",
    "        tio.RandomElasticDeformation(): 0.2,\n",
    "        tio.RandomAffine(scales=0.2, degrees=45, default_pad_value='otsu'): 0.8,\n",
    "    }, p=0.75),\n",
    "])\n",
    "\n",
    "common_transforms_2 = tio.Compose([\n",
    "    tio.RescaleIntensity((-1, 1.), (0.05, 99.5)),\n",
    "    ConcatenateImages(image_names=[\"flair_time01\", \"flair_time02\"], image_channels=[1, 1], new_image_name=\"X\"),\n",
    "    RenameProperty(old_name='ground_truth', new_name='y'),\n",
    "    CustomOneHot(include=\"y\"),\n",
    "])\n",
    "\n",
    "\n",
    "#augmentations = tio.RandomAffine(scales=0.2, degrees=45)\n",
    "#augmentations = tio.RandomElasticDeformation()\n",
    "intensity_augmentations = tio.Compose([\n",
    "    tio.RandomBiasField(p=0.5), \n",
    "    tio.RescaleIntensity((0, 1), (0.01, 99.9)),\n",
    "    tio.RandomGamma(p=0.8),\n",
    "    tio.RescaleIntensity((-1, 1)),\n",
    "    tio.RandomBlur((0, 1), p=0.2),\n",
    "    tio.RandomNoise(std=0.1, p=0.35)\n",
    "])\n",
    "\n",
    "subject = spatial_augmentations(subject)\n",
    "subject = intensity_augmentations(subject)\n",
    "subject = common_transforms_2(subject)\n",
    "\n",
    "img = subject['X'].data[None]\n",
    "print(img.shape)\n",
    "\n",
    "vis_features(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_features(x):\n",
    "    N, C, W, H, D = x.shape\n",
    "    \n",
    "    @interact(i=(0, N-1), c=(0, C-1), d=(0, D-1))\n",
    "    def plot_feature_map(i, c, d):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(x[i, c, :, :, d].cpu(), cmap=\"gray\")\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def vis_features(x):\n",
    "    N, C, W, H, D = x.shape\n",
    "    \n",
    "    @interact(i=(0, N-1), c=(0, C-1), d=(0, D-1))\n",
    "    def plot_feature_map(i, c, d):\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(x[i, c, :, :, d].cpu(), cmap=\"gray\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "def vis_model(x, model):\n",
    "    x = x.to(device)\n",
    "    modules = list(model.named_modules())\n",
    "    \n",
    "    @interact(module=modules[1:])\n",
    "    def select_module(module):\n",
    "    \n",
    "        def forward_module_hook(module, x_in, x_out):\n",
    "            vis_features(x_out.cpu())\n",
    "            \n",
    "        hook_handle = module.register_forward_hook(forward_module_hook)\n",
    "        with torch.no_grad():\n",
    "            model(x)\n",
    "        hook_handle.remove()\n",
    "\n",
    "model = ModularUNet(\n",
    "    in_channels=2, \n",
    "    out_channels=2, \n",
    "    filters=[32, 32, 32, 32, 32, 32], \n",
    "    depth=6,\n",
    "    block_params={\n",
    "        #'conv_class': WSConv3d,\n",
    "        #'normalization_class': None,\n",
    "        'residual': True,\n",
    "    },\n",
    "    downsample_class=BlurConv3d,\n",
    "    downsample_params={'kernel_size': 3, 'stride': 2, 'padding': 1, 'weight_standardization': False},\n",
    "    upsample_class=BlurConvTranspose3d,\n",
    "    upsample_params={'kernel_size': 3, 'stride': 2, 'padding': 1, 'output_padding': 0, 'weight_standardization': True},\n",
    ")\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "\n",
    "model = model.to(device)\n",
    "vis_model(img, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/diffusion_hippocampus.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/Diffusion_MRI/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/qsm_deep_grey_matter.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/DGM/segmentation_3T_ps18_v3/\")\n",
    "context = config.get_context(device, variables)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_module(\"./configs/msseg2.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/MSSEG2_processed/\")\n",
    "context = config.get_context(device, variables, fold=2)\n",
    "context.init_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *\n",
    "import torchio as tio\n",
    "\n",
    "config = load_module(\"./configs/msseg2.py\")\n",
    "\n",
    "variables = dict(DATASET_PATH=\"X:/Datasets/MSSEG2_processed/\")\n",
    "context = config.get_context(device, variables, fold=2)\n",
    "context.init_components()\n",
    "\n",
    "subject_loader = ComposeLoaders([\n",
    "    ImageLoader(glob_pattern=\"cv1-ens1-flips-5fold-majority*\", image_name='cv1-ens1-flips-5fold-majority', image_constructor=tio.LabelMap,\n",
    "                label_values={\"lesion\": 1})\n",
    "])\n",
    "context.dataset.load_additional_data('X:/Predictions/MSSEG2/', subject_loader)\n",
    "\n",
    "context.dataset.all_subjects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms import *\n",
    "subjects = [copy.deepcopy(subject) for subject in context.dataset.all_subjects]\n",
    "for subject in subjects:\n",
    "    \n",
    "subjects = [CustomOneHot()(subject) for subject in context.dataset.all_subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluators import *\n",
    "\n",
    "seg_eval = SegmentationEvaluator('cv1-ens1-flips-5fold-majority', 'ground_truth')\n",
    "evaluation = seg_eval(context.dataset.all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "from transforms import *\n",
    "from data_processing import *\n",
    "from evaluators import *\n",
    "import os\n",
    "\n",
    "subject_loader = ComposeLoaders([\n",
    "    ImageLoader(glob_pattern=\"flair_time01*\", image_name='flair_time01', image_constructor=tio.ScalarImage),\n",
    "    ImageLoader(glob_pattern=\"flair_time02*\", image_name='flair_time02', image_constructor=tio.ScalarImage),\n",
    "    ImageLoader(glob_pattern=\"brain_mask.*\", image_name='brain_mask', image_constructor=tio.LabelMap,\n",
    "                label_values={\"brain\": 1}),\n",
    "    ImageLoader(glob_pattern=\"ground_truth.*\", image_name=\"ground_truth\", image_constructor=tio.LabelMap,\n",
    "                label_values={\"lesion\": 1}\n",
    "                ),\n",
    "])\n",
    "transforms = tio.Compose([\n",
    "    SetDataType(torch.float),\n",
    "    EnforceConsistentAffine(source_image_name='flair_time01'),\n",
    "    TargetResample(target_spacing=1, tolerance=0.11, image_interpolation='bspline'),\n",
    "    CropToMask('brain_mask'),\n",
    "])\n",
    "\n",
    "dataset = SubjectFolder(root=\"X:/Datasets/MSSEG2_processed/\", subject_path=\"\", subject_loader=subject_loader, transforms=transforms)\n",
    "\n",
    "out_folder = \"X:/Datasets/MSSEG2_resampled/\"\n",
    "for subject in dataset:\n",
    "    subject_folder = os.path.join(out_folder, subject.name)\n",
    "    if not os.path.exists(subject_folder):\n",
    "        os.makedirs(subject_folder)\n",
    "    subject['flair_time01'].save(os.path.join(subject_folder, 'flair_time01_on_middle_space.nii.gz'))\n",
    "    subject['flair_time02'].save(os.path.join(subject_folder, 'flair_time02_on_middle_space.nii.gz'))\n",
    "    subject['brain_mask'].save(os.path.join(subject_folder, 'brain_mask.nii.gz'))\n",
    "    subject['ground_truth'].save(os.path.join(subject_folder, 'ground_truth.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-component",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_voxels = []\n",
    "brain_voxels = []\n",
    "total_voxels = []\n",
    "for i in range(len(context.dataset)):\n",
    "    subject = context.dataset[i]\n",
    "    W, H, D = subject.spatial_shape\n",
    "    total_voxels.append(W * H * D)\n",
    "    lesion_voxels.append(subject['y'].data[1].sum().item())\n",
    "    brain_voxels.append(subject['brain_mask'].data.sum().item())\n",
    "    if i % 5 == 0:\n",
    "        print(lesion_voxels, brain_voxels, total_voxels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / (torch.tensor(lesion_voxels) / torch.tensor(brain_voxels)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(context.dataset)\n",
    "\n",
    "training_dataset = context.dataset.get_cohort_dataset(\"training\")\n",
    "\n",
    "validation_filter = context.trainer.get_filter_from_scheduled_evaluations(\n",
    "    context.dataset, \n",
    "    context.trainer.validation_evaluators,\n",
    ")\n",
    "validation_dataset = context.dataset.get_cohort_dataset(validation_filter)\n",
    "\n",
    "validation_filter = context.trainer.get_filter_from_scheduled_evaluations(\n",
    "    context.dataset, \n",
    "    context.trainer.validation_evaluators,\n",
    "    include_fold_filters=False\n",
    ")\n",
    "\n",
    "print(validation_filter.filters)\n",
    "validation_dataset.set_cohort(validation_filter)\n",
    "\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "def dont_collate(subjects):\n",
    "    return subjects\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset,\n",
    "                                   batch_size=16,\n",
    "                                   sampler=SequentialSampler(validation_dataset),\n",
    "                                   collate_fn=dont_collate,\n",
    "                                   num_workers=0)\n",
    "\n",
    "print(len(training_dataset), len(validation_dataset))\n",
    "\n",
    "for subjects in validation_dataloader:\n",
    "    print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "\n",
    "for i in range(len(context.dataset)):\n",
    "    \n",
    "    '''\n",
    "    untransformed_subject = context.dataset.subjects[i]\n",
    "    \n",
    "    image_dict = untransformed_subject.get_images_dict(intensity_only=False)\n",
    "    \n",
    "    print(untransformed_subject.name)\n",
    "    for (image_name1, image1), (image_name2, image2) in combinations(image_dict.items(), 2):\n",
    "        print(f'{image_name1}.affine - {image_name2}.affine')\n",
    "        print(image1.affine - image2.affine)'''\n",
    "    \n",
    "    subject = context.dataset[i]\n",
    "    \n",
    "    print(subject.name)\n",
    "    print(subject.spacing, subject.spatial_shape)\n",
    "    \n",
    "    patch_size=96\n",
    "    sampler = tio.GridSampler(subject=subject, patch_size=patch_size, patch_overlap=patch_size // 2, padding_mode=None)\n",
    "    print(\"num_patches =\", len(sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms import *\n",
    "import copy\n",
    "\n",
    "for i in range(len(context.dataset)):\n",
    "    subject = context.dataset.subjects[i]\n",
    "    subject = copy.deepcopy(subject)\n",
    "    \n",
    "    pre_spacing = subject.get_first_image().spacing\n",
    "    \n",
    "    post_spacing = context.dataset[i].get_first_image().spacing\n",
    "    \n",
    "    pre_spacing = tuple([round(s, 3) for s in pre_spacing])\n",
    "    post_spacing = tuple([round(s, 3) for s in post_spacing])\n",
    "    \n",
    "    print(pre_spacing, post_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchio as tio\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "patch_size = 96\n",
    "queue_length = 300\n",
    "samples_per_volume = 10\n",
    "\n",
    "sampler = tio.data.UniformSampler(patch_size)\n",
    "patches_queue = tio.Queue(\n",
    "    context.dataset,\n",
    "    queue_length,\n",
    "    samples_per_volume,\n",
    "    sampler,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "patches_loader = DataLoader(dataset=patches_queue, batch_size=2, collate_fn=context.dataset.collate)\n",
    "\n",
    "num_epochs = 2\n",
    "model = torch.nn.Identity()\n",
    "for epoch_index in range(num_epochs):\n",
    "    for patches_batch in patches_loader:\n",
    "        print(patches_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in context.dataset.all_subjects:\n",
    "    img = subject['flair_time01']\n",
    "    img.load()\n",
    "    print(img.spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "#print(inspect.getsourcefile(context.model.__class__))\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-relation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasd_dataset = context.dataset.get_cohort_dataset('fasd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasd_dataset.preload_and_transform_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "untransformed_subject = context.dataset.subjects[0]\n",
    "print(\"Original labels:\")\n",
    "print(untransformed_subject['whole_roi']['label_values'])\n",
    "\n",
    "subject = context.dataset[0]\n",
    "print(\"\\nTransformed labels:\")\n",
    "print(subject['y']['label_values'])\n",
    "\n",
    "inverse_subject = subject.apply_inverse_transform(warn=False)\n",
    "print(\"\\nInverse transformed labels:\")\n",
    "print(inverse_subject['y']['label_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in context.dataset[1].items():\n",
    "    print(key, value, type(value))\n",
    "    if isinstance(value, dict):\n",
    "        for key, value2 in value.items():\n",
    "            print(key, value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "           \n",
    "for i in range(2):\n",
    "    loader = sample_data(context.dataloader)\n",
    "    batch = next(loader)\n",
    "    for key, val in batch.items():\n",
    "        print(key, val.shape, val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(20, 20, 20)\n",
    "for y in x.split([3, 2, 5, 10]):\n",
    "    print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"test-project-2\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    log_dict = {\n",
    "        'something': {\n",
    "            foo: {'mean': random.random(), 'std': random.random()}\n",
    "            for foo in \"ABC\"\n",
    "        }\n",
    "    }\n",
    "    wandb.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(10):\n",
    "    evaluation = {}\n",
    "    \n",
    "    for structure in (\"A\", \"B\", \"C\"):\n",
    "        columns = [\"TP\", \"FP\", \"TN\", \"FN\", 'dice', \"jaccard\"]\n",
    "        S = 25\n",
    "        subjects = [f'subject_{i:01}' for i in range(S)]\n",
    "\n",
    "        df = pd.DataFrame(data=np.random.randint(50, 100, size=(S, 4)), columns=[\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "        df.insert(loc=0, column='Subject', value=subjects)\n",
    "\n",
    "        TP, FP, TN, FN = df[\"TP\"], df[\"FP\"], df[\"TN\"], df[\"FN\"]\n",
    "\n",
    "        df['dice'] = 2 * TP / (2 * TP + FP + FN)\n",
    "        df['jaccard'] = TP / (TP + FP + FN)\n",
    "        evaluation[f\"Structure {structure}\"] = wandb.Table(dataframe=df)\n",
    "        \n",
    "    wandb.log({f'Segmentation Evaluation': evaluation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'X:\\Datasets\\Diffusion_MRI\\Attributes\\demographics.xlsx'\n",
    "df = pd.read_excel(file_path, index_col=0)\n",
    "#subject_col = df.columns[0]\n",
    "data = df.to_dict(orient='dict')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "print(pathlib.Path('yourPath.example').suffix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'X:\\Datasets\\DGM\\subject_attributes\\dgm_label_names.json'\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'X:\\Datasets\\DGM\\subject_attributes\\dgm_label_names.csv'\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "data = df.to_dict()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import is_sequence\n",
    "\n",
    "def test_func(*args):\n",
    "    if is_sequence(args) and len(args) == 1 and is_sequence(args[0]):\n",
    "        args = args[0]\n",
    "    print(args)\n",
    "    \n",
    "test_func(\"a\", \"b\", \"c\")\n",
    "test_func((\"a\", \"b\", \"c\"))\n",
    "test_func([\"a\", \"b\", \"c\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 0, 1]).bool()\n",
    "b = torch.tensor([1, 1, 0]).bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "import torch\n",
    "from evaluators import SegmentationEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "def pd_to_dict(elem):\n",
    "    if isinstance(elem, dict):\n",
    "        return {\n",
    "            key: pd_to_wandb(val)\n",
    "            for key, val in elem.items()\n",
    "        }\n",
    "    elif isinstance(elem, pd.DataFrame):\n",
    "        return elem.to_dict()\n",
    "    return elem\n",
    "\n",
    "def pd_to_wandb(elem):\n",
    "    if isinstance(elem, dict):\n",
    "        return {\n",
    "            key: pd_to_wandb(val)\n",
    "            for key, val in elem.items()\n",
    "        }\n",
    "    elif isinstance(elem, pd.DataFrame):\n",
    "        return wandb.Table(dataframe=elem)\n",
    "    return elem\n",
    "\n",
    "wandb.init(project=\"test-project-4\")\n",
    "for i in range(10):\n",
    "    label_values = {letter: val for val, letter in enumerate(\"ABCDE\")}\n",
    "\n",
    "    subjects = [\n",
    "        tio.Subject({\n",
    "            'name': f'subject_{i:02}',\n",
    "            'pred': tio.LabelMap(\n",
    "                tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "                label_values=label_values\n",
    "            ),\n",
    "            'target': tio.LabelMap(\n",
    "                tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "                label_values=label_values\n",
    "            ),\n",
    "        })\n",
    "        for i in range(20)\n",
    "    ]\n",
    "\n",
    "    seg_evaluator = SegmentationEvaluator(\n",
    "        prediction_label_name='pred', target_label_name='target', stats_to_output=['FP', 'TP', 'dice'], \n",
    "    )\n",
    "\n",
    "    log_dict = seg_evaluator(subjects)\n",
    "    wandb.log(pd_to_wandb(log_dict))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = tio.LabelMap(\n",
    "    tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "    label_values=label_values\n",
    ")\n",
    "\n",
    "tio.OneHot()(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10).unsqueeze(1)\n",
    "mask = torch.tensor([0, 1, 1, 0]).bool().unsqueeze(0)\n",
    "x, mask = torch.broadcast_tensors(x, mask)\n",
    "\n",
    "print(x.shape, mask.shape)\n",
    "\n",
    "x[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluators import VolumeStatsEvaluator\n",
    "import pandas as pd\n",
    "import torchio as tio\n",
    "\n",
    "\n",
    "label_values = {f'label_{letter}': (val + 1) for val, letter in enumerate(\"abcde\")}\n",
    "\n",
    "subjects = [\n",
    "    tio.Subject({\n",
    "        'name': f'subject_{i:02}',\n",
    "        'label': tio.LabelMap(\n",
    "            tensor=torch.randint(0, 5, size=(1, 20, 20, 20)),\n",
    "            label_values=label_values\n",
    "        ),\n",
    "        'md': tio.ScalarImage(\n",
    "            tensor=torch.randn(size=(1, 20, 20, 20)) * 2 + 1,\n",
    "        ),\n",
    "        'fa': tio.ScalarImage(\n",
    "            tensor=torch.randn(size=(1, 20, 20, 20)) * 0.5 - 3,\n",
    "        ),\n",
    "    })\n",
    "    for i in range(20)\n",
    "]\n",
    "\n",
    "volume_stats_eval = VolumeStatsEvaluator(\n",
    "    label_map_name='label', image_names=['md', 'fa']\n",
    ")\n",
    "\n",
    "volume_stats_eval(subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "def merge_dicts(a, b):\n",
    "    merged_dict = {}\n",
    "    for key in a.keys():\n",
    "        if key in b:\n",
    "            merged_dict[key] = merge_dicts(a[key], b[key])\n",
    "        else:\n",
    "            merged_dict[key] = a[key]\n",
    "    for key in b.keys():\n",
    "        if key not in a:\n",
    "            merged_dict[key] = b[key]\n",
    "    return merged_dict\n",
    "\n",
    "dict1 = {'mean': {'hippo': {'md': {'subject_1': 1}}}}\n",
    "dict2 = {'mean': {'hippo': {'md': {'subject_2': 2}}}}\n",
    "dict3 = {'mean': {'hippo': {'fa': {'subject_1': 3}}}}\n",
    "dict4 = {'mean': {'hippo': {'fa': {'subject_2': 4}}}}\n",
    "\n",
    "out_dict = merge_dicts(dict1, dict2)\n",
    "\n",
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *\n",
    "\n",
    "train_dataset = context.dataset.get_cohort_dataset(\n",
    "    RequireAttributes({\"pathologies\": \"None\", \"protocol\": \"cbbrain\", \"rescan_id\": \"None\"})\n",
    ")\n",
    "test_dataset = context.dataset.get_cohort_dataset(\n",
    "    'ab300'\n",
    ")\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for subject in train_dataset.all_subjects:\n",
    "    img_aff = subject[\"mean_dwi\"].affine\n",
    "    label_aff = subject['whole_roi'].affine\n",
    "    diff = img_aff - label_aff\n",
    "    if np.any(np.abs(diff) > 1e-6):\n",
    "        print(subject['name'])\n",
    "        print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_dataset_as_nn_unet\n",
    "from data_processing import *\n",
    "\n",
    "save_dataset_as_nn_unet(\n",
    "    context.dataset, \n",
    "    \"X:\\\\Datasets\\\\nnUNet_raw_data_base\\\\nnUNet_raw_data\\\\Task500_DMRI_Hippocampus_Whole\\\\\",\n",
    "    short_name=\"DMRI\", image_names=['mean_dwi', 'md', 'fa'], label_map_name='whole_roi',\n",
    "    train_cohort=RequireAttributes({\"pathologies\": \"None\", \"protocol\": \"cbbrain\", \"rescan_id\": \"None\"}),\n",
    "    test_cohort=None, #\"ab300\",\n",
    "    fix_affine=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context.dataset.all_subjects[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_dataset_as_nn_unet\n",
    "\n",
    "save_dataset_as_nn_unet(\n",
    "    context.dataset, \n",
    "    \"X:\\\\Datasets\\\\nnUNet_raw_data_base\\\\nnUNet_raw_data\\\\Task502_MSSEG2\\\\\",\n",
    "    short_name=\"MSSEG2\", image_names=['flair_time01', 'flair_time02'], label_map_name='ground_truth',\n",
    "    train_cohort = 'all'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = None\n",
    "{1:2, **({} if thing is None else thing), 3:4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RequireAttributes({\"pathologies\": \"None\", \"protocol\": \"cbbrain\", \"rescan_id\": \"None\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torchio as tio\n",
    "\n",
    "subject = context.dataset.all_subjects_map['cbbrain_192']\n",
    "subject = copy.deepcopy(subject)\n",
    "\n",
    "img_aff = subject[\"mean_dwi\"].affine\n",
    "label_aff = subject['whole_roi'].affine\n",
    "print(img_aff - label_aff)\n",
    "\n",
    "subject['whole_roi'].affine = subject['mean_dwi'].affine\n",
    "\n",
    "img_aff = subject[\"mean_dwi\"].affine\n",
    "label_aff = subject['whole_roi'].affine\n",
    "print(img_aff - label_aff)\n",
    "\n",
    "subject['whole_roi'].save('test_label.nii.gz')\n",
    "\n",
    "loaded_label = tio.LabelMap('test_label.nii.gz')\n",
    "print(img_aff - loaded_label.affine)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
